{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before your start:\n",
    "- Read the README.md file\n",
    "- Comment as much as you can and use the resources in the README.md file\n",
    "- Happy learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "import sklearn\n",
    "import statsmodels.api as smf\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - Explore the Scikit-Learn Datasets\n",
    "\n",
    "Before starting to work on our own datasets, let's first explore the datasets that are included in this Python library. These datasets have been cleaned and formatted for use in ML algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will load the diabetes dataset. Do this in the cell below by importing the datasets and then loading the dataset  to the `diabetes` variable using the `load_diabetes()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
       "          0.01990749, -0.01764613],\n",
       "        [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
       "         -0.06833155, -0.09220405],\n",
       "        [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
       "          0.00286131, -0.02593034],\n",
       "        ...,\n",
       "        [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
       "         -0.04688253,  0.01549073],\n",
       "        [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
       "          0.04452873, -0.02593034],\n",
       "        [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
       "         -0.00422151,  0.00306441]]),\n",
       " 'target': array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "         69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "         68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "         87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "        259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "        128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "        150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "        200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "         42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "         83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "        104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "        173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "        107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "         60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "        197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "         59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "        237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "        143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "        142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "         77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "         78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "        154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "         71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "        150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "        145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "         94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "         60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "         31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "        114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "        191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "        244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "        263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "         77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "         58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "        140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "        219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "         43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "        140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "         84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "         94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "        220.,  57.]),\n",
       " 'frame': None,\n",
       " 'DESCR': '.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n  :Number of Instances: 442\\n\\n  :Number of Attributes: First 10 columns are numeric predictive values\\n\\n  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n  :Attribute Information:\\n      - age     age in years\\n      - sex\\n      - bmi     body mass index\\n      - bp      average blood pressure\\n      - s1      tc, total serum cholesterol\\n      - s2      ldl, low-density lipoproteins\\n      - s3      hdl, high-density lipoproteins\\n      - s4      tch, total cholesterol / HDL\\n      - s5      ltg, possibly log of serum triglycerides level\\n      - s6      glu, blood sugar level\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttps://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\\n',\n",
       " 'feature_names': ['age',\n",
       "  'sex',\n",
       "  'bmi',\n",
       "  'bp',\n",
       "  's1',\n",
       "  's2',\n",
       "  's3',\n",
       "  's4',\n",
       "  's5',\n",
       "  's6'],\n",
       " 'data_filename': 'diabetes_data_raw.csv.gz',\n",
       " 'target_filename': 'diabetes_target.csv.gz',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "diabetes = sklearn.datasets.load_diabetes()\n",
    "diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore this variable by looking at the different attributes. Do this by looking at the `keys()` of this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'DESCR', 'feature_names', 'data_filename', 'target_filename', 'data_module'])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to read the description of the dataset. Print the description in the cell below using the `DESCR` attribute of the `diabetes` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - age     age in years\n",
      "      - sex\n",
      "      - bmi     body mass index\n",
      "      - bp      average blood pressure\n",
      "      - s1      tc, total serum cholesterol\n",
      "      - s2      ldl, low-density lipoproteins\n",
      "      - s3      hdl, high-density lipoproteins\n",
      "      - s4      tch, total cholesterol / HDL\n",
      "      - s5      ltg, possibly log of serum triglycerides level\n",
      "      - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(diabetes.DESCR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the variables in this dataset according to the description? List them in the markdown cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The variables are age,sex, body mass index, average blood and pressure, and six \n",
    "# blood serum measurements, acoording to what is said in the dataset description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enter your answer here:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now explore the data. Scikit-learn typically takes in 2D numpy arrays as input (though pandas dataframes are also accepted). In the cell below find the shape of the numpy array contained in the data portion of the diabetes variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 10)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes[\"data\"].shape\n",
    "#(422,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Supervised Learning on the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The data has already been split to predictor and response variables. The response variable is in the `target` portion of the variable. \n",
    "\n",
    "Given this information, let's apply what we have previously learned about linear regression and apply the algorithm to the diabetes dataset. In the cell below, import the linear regression class from sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression as LinReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the model in the variable `diabetes_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = diabetes[\"target\"]\n",
    "X = diabetes[\"data\"]\n",
    "diabetes_model = LinReg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, fit the model and print the intercept and coefficients of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152.13348416289597\n",
      "[ -10.0098663  -239.81564367  519.84592005  324.3846455  -792.17563855\n",
      "  476.73902101  101.04326794  177.06323767  751.27369956   67.62669218]\n"
     ]
    }
   ],
   "source": [
    "diabetes_model.fit(X, y)\n",
    "print(diabetes_model.intercept_)\n",
    "print(diabetes_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# for i in range(10):\n",
    "#     plt.figure(figsize=(5, 5))  # Adjust the figure size if needed\n",
    "#     sns.scatterplot(x=diabetes.data[:, i], y=diabetes.target)\n",
    "#     plt.title(f'Scatter Plot for Feature {i+1} vs Target')\n",
    "#     plt.xlabel(f'Feature {i+1}')\n",
    "#     plt.ylabel('Target Variable')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conduct a Hypothesis Test on the Model\n",
    "\n",
    "Once we have generated a linear model, we can test each coefficient using a t-test to see whether the confidence interval for the variable contains zero. We can also perform an overall F test to check whether at least one coefficient is significantly different from zero. \n",
    "\n",
    "Refer to the resource in this [link](https://onlinecourses.science.psu.edu/stat501/node/297/) for more details and perform the t-tests for the model above. Additionally, interpret the results and list coefficients are significantly different from zero.\n",
    "\n",
    "\n",
    "Hint: use the statsmodels package.\n",
    "\n",
    "Your result should look similar to this:\n",
    "\n",
    "![ols](../ols-results.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.518</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.507</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   46.27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 22 Nov 2023</td> <th>  Prob (F-statistic):</th> <td>3.83e-62</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:47:56</td>     <th>  Log-Likelihood:    </th> <td> -2386.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   442</td>      <th>  AIC:               </th> <td>   4794.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   431</td>      <th>  BIC:               </th> <td>   4839.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>  152.1335</td> <td>    2.576</td> <td>   59.061</td> <td> 0.000</td> <td>  147.071</td> <td>  157.196</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  -10.0099</td> <td>   59.749</td> <td>   -0.168</td> <td> 0.867</td> <td> -127.446</td> <td>  107.426</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td> -239.8156</td> <td>   61.222</td> <td>   -3.917</td> <td> 0.000</td> <td> -360.147</td> <td> -119.484</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>  519.8459</td> <td>   66.533</td> <td>    7.813</td> <td> 0.000</td> <td>  389.076</td> <td>  650.616</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>  324.3846</td> <td>   65.422</td> <td>    4.958</td> <td> 0.000</td> <td>  195.799</td> <td>  452.970</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td> -792.1756</td> <td>  416.680</td> <td>   -1.901</td> <td> 0.058</td> <td>-1611.153</td> <td>   26.802</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>  476.7390</td> <td>  339.030</td> <td>    1.406</td> <td> 0.160</td> <td> -189.620</td> <td> 1143.098</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>  101.0433</td> <td>  212.531</td> <td>    0.475</td> <td> 0.635</td> <td> -316.684</td> <td>  518.770</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>  177.0632</td> <td>  161.476</td> <td>    1.097</td> <td> 0.273</td> <td> -140.315</td> <td>  494.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>  751.2737</td> <td>  171.900</td> <td>    4.370</td> <td> 0.000</td> <td>  413.407</td> <td> 1089.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   67.6267</td> <td>   65.984</td> <td>    1.025</td> <td> 0.306</td> <td>  -62.064</td> <td>  197.318</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.506</td> <th>  Durbin-Watson:     </th> <td>   2.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.471</td> <th>  Jarque-Bera (JB):  </th> <td>   1.404</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.017</td> <th>  Prob(JB):          </th> <td>   0.496</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.726</td> <th>  Cond. No.          </th> <td>    227.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.518   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.507   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     46.27   \\\\\n",
       "\\textbf{Date:}             & Wed, 22 Nov 2023 & \\textbf{  Prob (F-statistic):} &  3.83e-62   \\\\\n",
       "\\textbf{Time:}             &     16:47:56     & \\textbf{  Log-Likelihood:    } &   -2386.0   \\\\\n",
       "\\textbf{No. Observations:} &         442      & \\textbf{  AIC:               } &     4794.   \\\\\n",
       "\\textbf{Df Residuals:}     &         431      & \\textbf{  BIC:               } &     4839.   \\\\\n",
       "\\textbf{Df Model:}         &          10      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &     152.1335  &        2.576     &    59.061  &         0.000        &      147.071    &      157.196     \\\\\n",
       "\\textbf{x1}    &     -10.0099  &       59.749     &    -0.168  &         0.867        &     -127.446    &      107.426     \\\\\n",
       "\\textbf{x2}    &    -239.8156  &       61.222     &    -3.917  &         0.000        &     -360.147    &     -119.484     \\\\\n",
       "\\textbf{x3}    &     519.8459  &       66.533     &     7.813  &         0.000        &      389.076    &      650.616     \\\\\n",
       "\\textbf{x4}    &     324.3846  &       65.422     &     4.958  &         0.000        &      195.799    &      452.970     \\\\\n",
       "\\textbf{x5}    &    -792.1756  &      416.680     &    -1.901  &         0.058        &    -1611.153    &       26.802     \\\\\n",
       "\\textbf{x6}    &     476.7390  &      339.030     &     1.406  &         0.160        &     -189.620    &     1143.098     \\\\\n",
       "\\textbf{x7}    &     101.0433  &      212.531     &     0.475  &         0.635        &     -316.684    &      518.770     \\\\\n",
       "\\textbf{x8}    &     177.0632  &      161.476     &     1.097  &         0.273        &     -140.315    &      494.441     \\\\\n",
       "\\textbf{x9}    &     751.2737  &      171.900     &     4.370  &         0.000        &      413.407    &     1089.140     \\\\\n",
       "\\textbf{x10}   &      67.6267  &       65.984     &     1.025  &         0.306        &      -62.064    &      197.318     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  1.506 & \\textbf{  Durbin-Watson:     } &    2.029  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.471 & \\textbf{  Jarque-Bera (JB):  } &    1.404  \\\\\n",
       "\\textbf{Skew:}          &  0.017 & \\textbf{  Prob(JB):          } &    0.496  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.726 & \\textbf{  Cond. No.          } &     227.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.518\n",
       "Model:                            OLS   Adj. R-squared:                  0.507\n",
       "Method:                 Least Squares   F-statistic:                     46.27\n",
       "Date:                Wed, 22 Nov 2023   Prob (F-statistic):           3.83e-62\n",
       "Time:                        16:47:56   Log-Likelihood:                -2386.0\n",
       "No. Observations:                 442   AIC:                             4794.\n",
       "Df Residuals:                     431   BIC:                             4839.\n",
       "Df Model:                          10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        152.1335      2.576     59.061      0.000     147.071     157.196\n",
       "x1           -10.0099     59.749     -0.168      0.867    -127.446     107.426\n",
       "x2          -239.8156     61.222     -3.917      0.000    -360.147    -119.484\n",
       "x3           519.8459     66.533      7.813      0.000     389.076     650.616\n",
       "x4           324.3846     65.422      4.958      0.000     195.799     452.970\n",
       "x5          -792.1756    416.680     -1.901      0.058   -1611.153      26.802\n",
       "x6           476.7390    339.030      1.406      0.160    -189.620    1143.098\n",
       "x7           101.0433    212.531      0.475      0.635    -316.684     518.770\n",
       "x8           177.0632    161.476      1.097      0.273    -140.315     494.441\n",
       "x9           751.2737    171.900      4.370      0.000     413.407    1089.140\n",
       "x10           67.6267     65.984      1.025      0.306     -62.064     197.318\n",
       "==============================================================================\n",
       "Omnibus:                        1.506   Durbin-Watson:                   2.029\n",
       "Prob(Omnibus):                  0.471   Jarque-Bera (JB):                1.404\n",
       "Skew:                           0.017   Prob(JB):                        0.496\n",
       "Kurtosis:                       2.726   Cond. No.                         227.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# H0: is that there is no relation between the all data features and the diabetes.\n",
    "# H1: is that there is relationship between the features and the diabetes.\n",
    "X = smf.add_constant(X)\n",
    "#results = smf.ols(\"target ~ data\", data = diabetes).fit()\n",
    "results = smf.OLS(y,X).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2 - Peform Supervised Learning on a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have looked at data that has been formatted for scikit-learn, let's look at data that we will need to format ourselves.\n",
    "\n",
    "In the next cell, load the `auto-mpg.csv` file included in this folder and assign it to a variable called `auto`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "auto = pd.read_csv('../auto-mpg.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the first 5 rows using the `head()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horse_power</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>car_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>\\t\"chevrolet chevelle malibu\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>\\t\"buick skylark 320\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>\\t\"plymouth satellite\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>\\t\"amc rebel sst\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>\\t\"ford torino\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horse_power  weight  acceleration  \\\n",
       "0  18.0          8         307.0        130.0    3504          12.0   \n",
       "1  15.0          8         350.0        165.0    3693          11.5   \n",
       "2  18.0          8         318.0        150.0    3436          11.0   \n",
       "3  16.0          8         304.0        150.0    3433          12.0   \n",
       "4  17.0          8         302.0        140.0    3449          10.5   \n",
       "\n",
       "   model_year                       car_name  \n",
       "0          70  \\t\"chevrolet chevelle malibu\"  \n",
       "1          70          \\t\"buick skylark 320\"  \n",
       "2          70         \\t\"plymouth satellite\"  \n",
       "3          70              \\t\"amc rebel sst\"  \n",
       "4          70                \\t\"ford torino\"  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "auto.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the data to ensure that all numeric columns are correctly detected as such by pandas. If a column is misclassified as object, coerce it to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   mpg           398 non-null    float64\n",
      " 1   cylinders     398 non-null    int64  \n",
      " 2   displacement  398 non-null    float64\n",
      " 3   horse_power   392 non-null    float64\n",
      " 4   weight        398 non-null    int64  \n",
      " 5   acceleration  398 non-null    float64\n",
      " 6   model_year    398 non-null    int64  \n",
      " 7   car_name      398 non-null    object \n",
      "dtypes: float64(4), int64(3), object(1)\n",
      "memory usage: 25.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "auto.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the newest model year and the oldest model year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "82\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "mini = min(auto[\"model_year\"])\n",
    "print(mini)\n",
    "maxi = max(auto[\"model_year\"])\n",
    "print(maxi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the dataset for missing values and remove all rows containing at least one missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 392 entries, 0 to 397\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   mpg           392 non-null    float64\n",
      " 1   cylinders     392 non-null    int64  \n",
      " 2   displacement  392 non-null    float64\n",
      " 3   horse_power   392 non-null    float64\n",
      " 4   weight        392 non-null    int64  \n",
      " 5   acceleration  392 non-null    float64\n",
      " 6   model_year    392 non-null    int64  \n",
      " 7   car_name      392 non-null    object \n",
      "dtypes: float64(4), int64(3), object(1)\n",
      "memory usage: 27.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "auto.isnull().sum()\n",
    "auto.dropna(inplace=True)\n",
    "auto.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the frequency table for the `cylinders` column using the `value_counts()` function. How many possible values of cylinders are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cylinders\n",
       "4    199\n",
       "8    103\n",
       "6     83\n",
       "3      4\n",
       "5      3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto[\"cylinders\"].value_counts()\n",
    "\n",
    "#There are 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to generate a linear regression model that will predict mpg. To do this, first drop the `car_name` column since it does not contain any quantitative data. Next separate the dataframe to predictor and response variables. Separate those into test and training data with 80% of the data in the training set and the remainder in the test set. \n",
    "\n",
    "Assign the predictor and response training data to `X_train` and `y_train` respectively. Similarly, assign the predictor and response test data to `X_test` and `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horse_power</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>car_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>\\t\"chevrolet chevelle malibu\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>\\t\"buick skylark 320\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>\\t\"plymouth satellite\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>\\t\"amc rebel sst\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>\\t\"ford torino\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>\\t\"ford mustang gl\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>\\t\"vw pickup\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>\\t\"dodge rampage\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>\\t\"ford ranger\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>\\t\"chevy s-10\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horse_power  weight  acceleration  \\\n",
       "0    18.0          8         307.0        130.0    3504          12.0   \n",
       "1    15.0          8         350.0        165.0    3693          11.5   \n",
       "2    18.0          8         318.0        150.0    3436          11.0   \n",
       "3    16.0          8         304.0        150.0    3433          12.0   \n",
       "4    17.0          8         302.0        140.0    3449          10.5   \n",
       "..    ...        ...           ...          ...     ...           ...   \n",
       "393  27.0          4         140.0         86.0    2790          15.6   \n",
       "394  44.0          4          97.0         52.0    2130          24.6   \n",
       "395  32.0          4         135.0         84.0    2295          11.6   \n",
       "396  28.0          4         120.0         79.0    2625          18.6   \n",
       "397  31.0          4         119.0         82.0    2720          19.4   \n",
       "\n",
       "     model_year                       car_name  \n",
       "0            70  \\t\"chevrolet chevelle malibu\"  \n",
       "1            70          \\t\"buick skylark 320\"  \n",
       "2            70         \\t\"plymouth satellite\"  \n",
       "3            70              \\t\"amc rebel sst\"  \n",
       "4            70                \\t\"ford torino\"  \n",
       "..          ...                            ...  \n",
       "393          82            \\t\"ford mustang gl\"  \n",
       "394          82                  \\t\"vw pickup\"  \n",
       "395          82              \\t\"dodge rampage\"  \n",
       "396          82                \\t\"ford ranger\"  \n",
       "397          82                 \\t\"chevy s-10\"  \n",
       "\n",
       "[392 rows x 8 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = auto.drop(columns=\"car_name\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = auto.drop(columns=\"mpg\")\n",
    "y = auto[\"mpg\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will test the dataset that we processed and peform linear regression on this data to predict the mpg for each vehicle. Initialize the model in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_model = LinReg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, fit the model in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here:\n",
    "auto_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3 - Evaluate the Model\n",
    "\n",
    "the r squared score of a model tells us how much variation is explained by the model. In a typical dataset, most observations differ from the mean. When we create a model, we are trying to generate an equation that will tell us by how much each observation will differ from the mean. Obviously, the vast majority of models are not perfect. They can only predict some of the variation from the mean but not all of it. We attribute the rest of the difference between the actual value and the mean to random error. We would like random error to explain the as little as possible of the variation. This is why the r squared score is an important metric.\n",
    "\n",
    "In the next cell, compute the r squared score of the model. Do this by first computing the predicted values and assign them to `y_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32.5032214 , 28.61387011, 19.47847725, 26.16161575, 31.00349495,\n",
       "       23.68772989, 25.84327357, 13.55693682, 32.12380669, 28.0556387 ,\n",
       "       21.55154864, 21.14857416, 16.2595604 , 17.91615718, 12.30402609,\n",
       "        9.69853469, 32.00297822, 12.53766261, 10.03666516, 33.50160579,\n",
       "       30.36480462, 29.59245781, 30.19176406, 33.24436377, 26.35592217,\n",
       "       27.59827488, 33.6241364 , 27.85070091, 28.87789652, 15.03089065,\n",
       "       26.60517023, 11.0785454 , 21.07784699, 15.12377781, 33.0809791 ,\n",
       "        9.7388948 , 28.20921163, 30.35306924, 24.64174786, 25.48294936,\n",
       "       13.81967699, 26.35737044, 19.6405416 , 12.82787774,  8.23298288,\n",
       "       27.28742164, 33.50823381, 25.6920757 , 26.80552802, 18.10417406,\n",
       "       31.39359384, 15.01180677, 32.19554162, 13.45854247, 16.21190054,\n",
       "       16.28050925, 28.58359898, 10.34262433, 32.55917961, 18.8223611 ,\n",
       "       30.17365061, 25.80723828,  9.73652788, 23.17315166, 24.91505779,\n",
       "       34.43449336, 28.79720498, 21.87262472, 24.68988386, 10.50464125,\n",
       "        9.91563965, 29.55415125, 23.71915378, 22.07147055, 29.49787243,\n",
       "       26.19616118, 32.06074902, 32.16511835, 25.49473678])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = auto_model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE, error: 2.7658614520566718\n",
      "MSE, error: 13.667338800726686\n",
      "RMSE, error: 3.6969364074496447\n",
      "r2: 0.8035180107891927\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(y_test)\n",
    "plt.legend();\n",
    "\n",
    "print(f\"MAE, error: {metrics.mean_absolute_error(y_test, y_pred)}\")\n",
    "print(f\"MSE, error: {metrics.mean_squared_error(y_test, y_pred)}\")\n",
    "print(f\"RMSE, error: {np.sqrt(metrics.mean_squared_error(y_test, y_pred))}\")\n",
    "print(f\"r2: {metrics.r2_score(y_test, y_pred)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our next step is to evaluate the model using the test data. We would like to ensure that our model is not overfitting the data. This means that our model will not be able to generalize well outside of the training data.\n",
    "\n",
    "In the cell below, use the model to generate the predicted values for the training data and assign them to `y_test_pred`. Compute the r squared score for the test data by comparing the oberserved `y_test` data and the predicted `y_test_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ytest prediction has r2: 0.8035180107891927\n",
      "Ytrain prediction has r2: 0.8088101169749278\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = auto_model.predict(X_train)\n",
    "print(f\"Ytest prediction has r2: {metrics.r2_score(y_test, y_pred)}\") \n",
    "print(f\"Ytrain prediction has r2: {metrics.r2_score(y_train, y_train_pred)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 4 - Improve the Model Fit\n",
    "\n",
    "While the most common way to improve the fit of a model is by using regularization, there are other simpler ways to improve model fit. The first is to create a simpler model. The second is to increase the train sample size.\n",
    "\n",
    "Let us start with the easier option and increase our train sample size to 90% of the data. Create a new test train split and name the new predictors and response variables `X_train09`, `X_test09`, `y_train09`, `y_test09`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train09,X_test09,y_train09,y_test09 = train_test_split(X, y, test_size = 0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a new model. Name this model `auto_model09`. Fit the model to the new sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_model09 = LinReg()\n",
    "auto_model09.fit(X_train09, y_train09)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the predicted values and r squared score for our new model and new sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred09 = auto_model09.predict(X_test09)\n",
    "sns.histplot(y_test09);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the r squared score for the smaller test set. Is there an improvement in the test r squared?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ytest09 prediction r2: 0.8391381938136697\n",
      "Ytrain09 prediction r2: 0.799751608652389\n",
      "Ytest08 prediction has r2: 0.8035180107891927\n",
      "Ytrain08 prediction has r2: 0.8088101169749278\n"
     ]
    }
   ],
   "source": [
    "y_train_pred09 = auto_model.predict(X_train09)\n",
    "print(f\"Ytest09 prediction r2: {metrics.r2_score(y_test09, y_pred09)}\")\n",
    "print(f\"Ytrain09 prediction r2: {metrics.r2_score(y_train09, y_train_pred09)}\")\n",
    "#Bigger set test\n",
    "print(f\"Ytest08 prediction has r2: {metrics.r2_score(y_test, y_pred)}\") \n",
    "print(f\"Ytrain08 prediction has r2: {metrics.r2_score(y_train, y_train_pred)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge 2 - Backward Elimination \n",
    "\n",
    "The main way to produce a simpler linear regression model is to reduce the number of variables used in the model. In scikit-learn, we can do this by using recursive feature elimination. You can read more about RFE [here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html).\n",
    "\n",
    "In the next cell, we will import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the documentation and initialize an RFE model using the `auto_model` linear regression model. Set `n_features_to_select=3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFE_model = sklearn.feature_selection.RFE(auto_model, n_features_to_select=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model and print the ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cylinders': 1,\n",
       " 'displacement': 4,\n",
       " 'horse_power': 2,\n",
       " 'weight': 3,\n",
       " 'acceleration': 1,\n",
       " 'model_year': 1}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "#auto_model.fit(X_train, y_train)\n",
    "RFE_model.fit(X_train, y_train)\n",
    "RFE_model.ranking_\n",
    "dict_ = {}\n",
    "for j, k in zip(RFE_model.ranking_, X_train.columns):\n",
    "    dict_[k] = j\n",
    "dict_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature importance is ranked from most important (1) to least important (4). Generate a model with the three most important features. The features correspond to variable names. For example, feature 1 is `cylinders` and feature 2 is `displacement`.\n",
    "\n",
    "Perform a test-train split on this reduced column data and call the split data `X_train_reduced`, `X_test_reduced`, `y_train_reduced`, `y_test_reduced`. Use an 80% split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: 0.6968438082022512\n"
     ]
    }
   ],
   "source": [
    "small_auto_model = auto[[\"cylinders\", \"acceleration\",\"model_year\"]]\n",
    "y_mpg = y\n",
    "X_train_reduced, X_test_reduced, y_train_reduced, y_test_reduced = train_test_split(small_auto_model, y_mpg, test_size = 0.2)\n",
    "\n",
    "new_model = LinReg()\n",
    "new_model.fit(X_train_reduced, y_train_reduced)\n",
    "\n",
    "y_pred_reduced = new_model.predict(X_test_reduced)\n",
    "\n",
    "print(f\"r2: {metrics.r2_score(y_test_reduced, y_pred_reduced)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a new model called `auto_model_reduced` and fit this model. Then proceed to compute the r squared score for the model. Did this cause an improvement in the r squared score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It did not improved the model. So a more correlation between the columns with the feature we want to \n",
    "# predict does not mean that R2 value has to be higher.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
